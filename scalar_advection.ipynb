{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be571a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-15 09:47:06.709995: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from clawpack import pyclaw\n",
    "from clawpack import riemann\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow import keras\n",
    "import os\n",
    "from IPython.display import display, Math, Latex\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error as mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e85d6e",
   "metadata": {},
   "source": [
    "First we will work on creating numerical solutions to the following pde (scalar advection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "060ce934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle q_{t} + uq_{x}=0$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Math(r'q_{t} + uq_{x}=0'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e492044a",
   "metadata": {},
   "source": [
    "To do this we will use a python package for finite volume methods, Clawpack.<br>\n",
    "We need to set up the functionality for creating a domain for Clawpack to run a simulation on.<br>\n",
    "The following function returns a domain and a solver. <br>\n",
    "The solver uses a 'SSP104' time integrator and a 5th order weno method.<br>\n",
    "We have set up a maximum CFL of 2.5 and periodic boundary conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0aab85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def claw_domain(domain=[0,1], nx=128):\n",
    "    riemann_solver = riemann.advection_1D\n",
    "    solver = pyclaw.SharpClawSolver1D(riemann_solver)\n",
    "    solver.weno_order = 5\n",
    "    solver.time_integrator = 'SSP104'\n",
    "    solver.kernel_language = 'Fortran'\n",
    "    solver.bc_lower[0] = pyclaw.BC.periodic\n",
    "    solver.bc_upper[0] = pyclaw.BC.periodic\n",
    "    solver.cfl_max = 2.5\n",
    "    x = pyclaw.Dimension(domain[0], domain[1], nx, name='x')\n",
    "    return pyclaw.Domain(x), solver\n",
    "test_domain, test_solver = claw_domain()\n",
    "test_state = pyclaw.State(test_domain, test_solver.num_eqn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fdbab0",
   "metadata": {},
   "source": [
    "For the initial conditions used during training and evaluation we will use the following functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81142cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#This is the IC for the 'amplitude'\n",
    "def qinit_train(state):\n",
    "    # Initial Data parameters\n",
    "    xc = state.grid.x.centers\n",
    "    center = np.random.uniform(0, 1, (2,))\n",
    "    freq = np.random.uniform(1, 4, (2,))\n",
    "    height = np.random.uniform(.05, .15, (1,))\n",
    "    state.q[0, :] = np.abs(np.sin(freq[0] * (xc - center[0])) + np.cos(freq[1] * (xc-center[1])) ** 2) + height\n",
    "#This is the IC for velocity (a scalar)\n",
    "def auxinit_train(state):\n",
    "    state.problem_data['u'] = np.random.choice(a=[-1, 1])\n",
    "\n",
    "#Printing out an example output\n",
    "qinit_train(test_state)\n",
    "auxinit_train(test_state)\n",
    "x = np.arange(0, 1, 1/128)\n",
    "plt.plot(x, test_state.q[0, :], color='black', label='Amplitude')\n",
    "plt.plot(x, np.full((128,), test_state.problem_data['u']), color='red', label='Velocity')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca34bca",
   "metadata": {},
   "source": [
    "Now we will create the functions to generate the initial conditions that are used in testing. The first function for amplitude has two exponential profiles. The second is a rectangular initial condition.<br>\n",
    "The first velocity function simply returns a velocity of 1. The second returns -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ed16383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#This is the testing IC for amplitude that is comprised of two exponential profiles\n",
    "def qinit_test_1(state):\n",
    "    xc = state.grid.x.centers\n",
    "    decay = [25, 100]\n",
    "    center = [.2, .8]\n",
    "    amplitude = [.9, 1.1]\n",
    "    state.q[0, :] = amplitude[0] * np.exp(-decay[0] * (xc - center[0])**2) + amplitude[1] * np.exp(-decay[1] * (xc - center[1])**2)\n",
    "#This is the rectangular testing IC for amplitude\n",
    "def qinit_test_2(state):\n",
    "    xc = state.grid.x.centers\n",
    "    h1 = .2\n",
    "    h2 = 1\n",
    "    length = .4\n",
    "    start = .2\n",
    "    state.q[0, :] = h1 + h2 * (xc >= start) * (xc <= (start + length))\n",
    "#This creates a velocity of +1\n",
    "def auxinit_test_1(state):\n",
    "    # Initilize petsc Structures for aux\n",
    "    state.problem_data['u'] = 1\n",
    "#This creates a velocity of -1\n",
    "def auxinit_test_1(state):\n",
    "    # Initilize petsc Structures for aux\n",
    "    state.problem_data['u'] = -1\n",
    "\n",
    "#Printing out both test ICs for amplitude\n",
    "qinit_test_1(test_state)\n",
    "plt.plot(x, test_state.q[0, :], color='black', label='Amplitude 1')\n",
    "qinit_test_2(test_state)\n",
    "plt.plot(x, test_state.q[0, :], color='red', label='Amplitude 2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388fa27d",
   "metadata": {},
   "source": [
    "Now we will create the function for creating the training data. You pass parameters for the reference dimension, the dimension that you want to downsample to, the number of steps and the final time of the simulation (determining dt for a single step on each initial condition), the number of training examples, and the directory where you'd like to store the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6be8d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_train(ref_dimensions, dimensions, nsteps, tfinal, num_train, outdir):\n",
    "    for i in range(num_train):\n",
    "        domain, solver = claw_domain(domain=[0, 1], nx=ref_dimensions)\n",
    "        state = pyclaw.State(domain, solver.num_eqn)\n",
    "        auxinit_train(state)\n",
    "        qinit_train(state)\n",
    "        claw = pyclaw.Controller()\n",
    "        claw.outdir = outdir + '/_output'\n",
    "        claw.solution = pyclaw.Solution(state, domain)\n",
    "        claw.solver = solver\n",
    "        claw.num_output_times = 1\n",
    "        claw.tfinal = tfinal / nsteps\n",
    "        claw.keep_copy = True\n",
    "        claw.run()\n",
    "        inp = np.expand_dims(down_sample(claw.frames[0].q[0], dimensions=ref_dimensions, factor=8), axis=-1)\n",
    "        out = np.expand_dims(down_sample(claw.frames[-1].q[0], dimensions=ref_dimensions, factor=8), axis=-1)\n",
    "        u = np.full((dimensions, 1), claw.frames[0].problem_data['u'])\n",
    "        np.save(outdir + '/training/ex_' + str(i) + '.npy', np.concatenate([inp, u, out], axis=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81331b9",
   "metadata": {},
   "source": [
    "The function for creating the validation data is almost identical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93cb448b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_val(ref_dimensions, dimensions, nsteps, tfinal, num_val, outdir):\n",
    "    for i in range(num_val):\n",
    "        domain, solver = claw_domain(domain=[0, 1], nx=ref_dimensions)\n",
    "        state = pyclaw.State(domain, solver.num_eqn)\n",
    "        auxinit_train(state)\n",
    "        qinit_train(state)\n",
    "        claw = pyclaw.Controller()\n",
    "        claw.outdir = outdir + '/_output'\n",
    "        claw.solution = pyclaw.Solution(state, domain)\n",
    "        claw.solver = solver\n",
    "        claw.num_output_times = 1\n",
    "        claw.tfinal = tfinal / nsteps\n",
    "        claw.keep_copy = True\n",
    "        claw.run()\n",
    "        inp = np.expand_dims(down_sample(claw.frames[0].q[0], dimensions=ref_dimensions, factor=8), axis=-1)\n",
    "        out = np.expand_dims(down_sample(claw.frames[-1].q[0], dimensions=ref_dimensions, factor=8), axis=-1)\n",
    "        u = np.full((dimensions, 1), claw.frames[0].problem_data['u'])\n",
    "        np.save(outdir + '/validation/ex_' + str(i) + '.npy', np.concatenate([inp, u, out], axis=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86daf8d",
   "metadata": {},
   "source": [
    "The function for generating the test data is slightly different. We generate numerical solutions from 1/2 to 16 times the base resolution and downsample each by factors of 1 (no downsampling), 2, 4, and 8 to 1/2x, 1x, and 2x the base resolution (128 by default). The deep learning model weights are applied at resolutions of 1/2x, 1x, and 2x the base resolution (trained on 1x). At each of those resolutions the output of the deep learning model is compared to the numerical solutions at 1, 2, 4, and 8 times resolution that have been downsampled by that same factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cf32063",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_test(dimensions, nsteps, tfinal, outdir):\n",
    "    print('Done generating training and validation data, starting with the generation of simulations for test cases')\n",
    "    for mult in [1/2, 1, 2, 4, 8, 16]:\n",
    "        domain, solver = claw_domain(nx=int(dimensions * mult))\n",
    "        state = pyclaw.State(domain, solver.num_eqn)\n",
    "\n",
    "        auxinit_test_1(state)\n",
    "        qinit_test_1(state)\n",
    "\n",
    "        for i in range(nsteps):\n",
    "            print(i, mult)\n",
    "            claw = pyclaw.Controller()\n",
    "            claw.outdir = outdir + '/_output'\n",
    "            claw.solution = pyclaw.Solution(state, domain)\n",
    "            claw.solver = solver\n",
    "            claw.num_output_times = 1\n",
    "            claw.tfinal = tfinal / nsteps\n",
    "            claw.keep_copy = True\n",
    "\n",
    "            claw.run()\n",
    "            next_ = claw.frames[-1].q[0]\n",
    "            last = claw.frames[0].q[0]\n",
    "\n",
    "            if mult >= 1/2 and mult <= 4:\n",
    "                np.save(outdir+'/testing/'+str(int(mult * dimensions)) + '->' + str(int(dimensions / 2)) + '_step:' + str(i) + '.npy', down_sample(last, dimensions * mult, int(mult * 2)))\n",
    "            if mult >= 1 and mult <= 8:\n",
    "                np.save(outdir+'/testing/' + str(int(mult * dimensions)) + '->' + str(int(dimensions)) + '_step:' + str(i) + '.npy', down_sample(last, dimensions * mult, int(mult)))\n",
    "            if mult >= 2 and mult <= 16:\n",
    "                np.save(outdir+'/testing/' + str(int(mult * dimensions)) + '->' + str(int(dimensions * 2)) + '_step:' + str(i) + '.npy', down_sample(last, dimensions * mult, int(mult / 2)))\n",
    "\n",
    "            state = pyclaw.State(domain, solver.num_eqn)\n",
    "            state.q[0, :] = next_\n",
    "            auxinit_test_1(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d0af9f",
   "metadata": {},
   "source": [
    "Now we will create a simple wrapper function for gen_train, gen_val, and gen_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "730f7b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data(outdir, dimensions=128, nsteps=128, tfinal=1.0, num_train=20000, num_val=5000):\n",
    "    # generate 'num_train' training pairs\n",
    "    # run training for model by taking 1 timestep of size tfinal/nsteps at 8x resolution for a numerical model\n",
    "    # - 8x resolution is the reference solution\n",
    "    ref_dimensions = 8 * dimensions\n",
    "    gen_train(ref_dimensions, dimensions, nsteps, tfinal, num_train, outdir)\n",
    "    gen_val(ref_dimensions, dimensions, nsteps, tfinal, num_val, outdir)\n",
    "    gen_test(dimensions, nsteps, tfinal, outdir)\n",
    "    # run evaluation for model at its original training resolution as well as at double and half the resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18953237",
   "metadata": {},
   "source": [
    "We can start on the deep learning models now. First we will define a Unet model. Padding for all models has been done with lambda layers that connect feature maps on the boundaries in a way consistent with periodic boundary conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d1c8f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def UNet(pretrained_weights=None, input_shape=(128, 2)):\n",
    "    inputs = Input(input_shape)\n",
    "    periodic_padd = Lambda(lambda b: tf.concat([tf.slice(b, [0, input_shape[0]-1, 0], [-1, -1, -1]), b, tf.slice(b, [0, 0, 0], [-1, 1, -1])], axis=1))\n",
    "    conv1 = Conv1D(64, 3, activation='tanh', padding='valid', kernel_initializer='he_normal')(periodic_padd(BatchNormalization(axis=[1, 2])(inputs)))\n",
    "    conv1 = Conv1D(64, 3, activation='tanh', padding='valid', kernel_initializer='he_normal')(periodic_padd(BatchNormalization(axis=[1, 2])(conv1)))\n",
    "    pool1 = AveragePooling1D(pool_size=2)(conv1)\n",
    "    periodic_padd = Lambda(lambda b: tf.concat(\n",
    "        [tf.slice(b, [0, int(input_shape[0]/2) - 1, 0], [-1, -1, -1]), b, tf.slice(b, [0, 0, 0], [-1, 1, -1])], axis=1))\n",
    "    conv2 = Conv1D(128, 3, activation='tanh', padding='valid', kernel_initializer='he_normal')(periodic_padd(BatchNormalization(axis=[1, 2])(pool1)))\n",
    "    conv2 = Conv1D(128, 3, activation='tanh', padding='valid', kernel_initializer='he_normal')(periodic_padd(BatchNormalization(axis=[1, 2])(conv2)))\n",
    "    pool2 = AveragePooling1D(pool_size=2)(conv2)\n",
    "    periodic_padd = Lambda(lambda b: tf.concat(\n",
    "        [tf.slice(b, [0, int(input_shape[0] / 4) - 1, 0], [-1, -1, -1]), b, tf.slice(b, [0, 0, 0], [-1, 1, -1])],\n",
    "        axis=1))\n",
    "    conv3 = Conv1D(256, 3, activation='tanh', padding='valid', kernel_initializer='he_normal')(periodic_padd(BatchNormalization(axis=[1, 2])(pool2)))\n",
    "    conv3 = Conv1D(256, 3, activation='tanh', padding='valid', kernel_initializer='he_normal')(periodic_padd(BatchNormalization(axis=[1, 2])(conv3)))\n",
    "    pool3 = AveragePooling1D(pool_size=2)(conv3)\n",
    "    periodic_padd = Lambda(lambda b: tf.concat(\n",
    "        [tf.slice(b, [0, int(input_shape[0] / 8) - 1, 0], [-1, -1, -1]), b, tf.slice(b, [0, 0, 0], [-1, 1, -1])],\n",
    "        axis=1))\n",
    "    conv4 = Conv1D(512, 3, activation='tanh', padding='valid', kernel_initializer='he_normal')(periodic_padd(BatchNormalization(axis=[1, 2])(pool3)))\n",
    "    conv4 = Conv1D(512, 3, activation='tanh', padding='valid', kernel_initializer='he_normal')(periodic_padd(BatchNormalization(axis=[1, 2])(conv4)))\n",
    "    pool4 = AveragePooling1D(pool_size=2)(conv4)\n",
    "    periodic_padd = Lambda(lambda b: tf.concat(\n",
    "        [tf.slice(b, [0, int(input_shape[0] / 16) - 1, 0], [-1, -1, -1]), b, tf.slice(b, [0, 0, 0], [-1, 1, -1])],\n",
    "        axis=1))\n",
    "    conv5 = Conv1D(1024, 3, activation='tanh', padding='valid', kernel_initializer='he_normal')(periodic_padd(BatchNormalization(axis=[1, 2])(pool4)))\n",
    "    conv5 = Conv1D(1024, 3, activation='tanh', padding='valid', kernel_initializer='he_normal')(periodic_padd(BatchNormalization(axis=[1, 2])(conv5)))\n",
    "    drop5 = Dropout(0.2)(conv5)\n",
    "    periodic_padd_2 = Lambda(lambda b: tf.concat([b, tf.slice(b, [0, 0, 0], [-1, 1, -1])], axis=1))\n",
    "    up6 = Conv1D(512, 2, activation='tanh', padding='valid', kernel_initializer='he_normal')(periodic_padd_2(BatchNormalization(axis=[1, 2])(\n",
    "        UpSampling1D(size=2)(drop5))))\n",
    "    periodic_padd = Lambda(lambda b: tf.concat(\n",
    "        [tf.slice(b, [0, int(input_shape[0] / 8) - 1, 0], [-1, -1, -1]), b, tf.slice(b, [0, 0, 0], [-1, 1, -1])],\n",
    "        axis=1))\n",
    "    merge6 = concatenate([conv4, up6], axis=-1)\n",
    "    conv6 = Conv1D(512, 3, activation='tanh', padding='valid', kernel_initializer='he_normal')(periodic_padd(BatchNormalization(axis=[1, 2])(merge6)))\n",
    "    conv6 = Conv1D(512, 3, activation='tanh', padding='valid', kernel_initializer='he_normal')(periodic_padd(BatchNormalization(axis=[1, 2])(conv6)))\n",
    "\n",
    "    up7 = Conv1D(256, 2, activation='tanh', padding='valid', kernel_initializer='he_normal')(periodic_padd_2(BatchNormalization(axis=[1, 2])(\n",
    "        UpSampling1D(size=2)(conv6))))\n",
    "    periodic_padd = Lambda(lambda b: tf.concat(\n",
    "        [tf.slice(b, [0, int(input_shape[0] / 4) - 1, 0], [-1, -1, -1]), b, tf.slice(b, [0, 0, 0], [-1, 1, -1])],\n",
    "        axis=1))\n",
    "    merge7 = concatenate([conv3, up7], axis=-1)\n",
    "    conv7 = Conv1D(256, 3, activation='tanh', padding='valid', kernel_initializer='he_normal')(periodic_padd(BatchNormalization(axis=[1, 2])(merge7)))\n",
    "    conv7 = Conv1D(256, 3, activation='tanh', padding='valid', kernel_initializer='he_normal')(periodic_padd(BatchNormalization(axis=[1, 2])(conv7)))\n",
    "\n",
    "    up8 = Conv1D(128, 2, activation='tanh', padding='valid', kernel_initializer='he_normal')(periodic_padd_2(BatchNormalization(axis=[1, 2])(\n",
    "        UpSampling1D(size=2)(conv7))))\n",
    "    periodic_padd = Lambda(lambda b: tf.concat(\n",
    "        [tf.slice(b, [0, int(input_shape[0] / 2) - 1, 0], [-1, -1, -1]), b, tf.slice(b, [0, 0, 0], [-1, 1, -1])],\n",
    "        axis=1))\n",
    "    merge8 = concatenate([conv2, up8], axis=-1)\n",
    "    conv8 = Conv1D(128, 3, activation='tanh', padding='valid', kernel_initializer='he_normal')(periodic_padd(BatchNormalization(axis=[1, 2])(merge8)))\n",
    "    conv8 = Conv1D(128, 3, activation='tanh', padding='valid', kernel_initializer='he_normal')(periodic_padd(BatchNormalization(axis=[1, 2])(conv8)))\n",
    "\n",
    "    up9 = Conv1D(64, 2, activation='tanh', padding='valid', kernel_initializer='he_normal')(periodic_padd_2(BatchNormalization(axis=[1, 2])(\n",
    "        UpSampling1D(size=2)(conv8))))\n",
    "    periodic_padd = Lambda(lambda b: tf.concat(\n",
    "        [tf.slice(b, [0, input_shape[0] - 1, 0], [-1, -1, -1]), b, tf.slice(b, [0, 0, 0], [-1, 1, -1])],\n",
    "        axis=1))\n",
    "    merge9 = concatenate([conv1, up9], axis=-1)\n",
    "    conv9 = Conv1D(48, 3, activation='tanh', padding='valid', kernel_initializer='he_normal')(periodic_padd(BatchNormalization(axis=[1, 2])(merge9)))\n",
    "    conv9 = Conv1D(16, 3, activation='tanh', padding='valid', kernel_initializer='he_normal')(periodic_padd(BatchNormalization(axis=[1, 2])(conv9)))\n",
    "    out = Conv1D(1, 1, activation='tanh', kernel_initializer='he_normal')(conv9)\n",
    "    model = Model(inputs=inputs, outputs=out, name='UNet_1')\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr=1e-3), loss='mae', metrics=['mae'])\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    if (pretrained_weights):\n",
    "        model.load_weights(pretrained_weights)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b627740e",
   "metadata": {},
   "source": [
    "Next we will give a second UNet where the velocity and amplitude input fields are multiplied together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3cc8b92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def UNet2(pretrained_weights=None, input_shape=(128, 2)):\n",
    "    inputs = Input(input_shape)\n",
    "    input1 = Lambda(lambda b: tf.slice(b, [0, 0, 0], [-1, -1, 1]))(inputs)\n",
    "    velocities = Lambda(lambda b: tf.slice(b, [0, 0, 1], [-1, -1, -1]))(inputs)\n",
    "    v_times_in = multiply([input1, velocities])\n",
    "    periodic_padd = Lambda(lambda b: tf.concat([tf.slice(b, [0, input_shape[0]-1, 0], [-1, -1, -1]), b, tf.slice(b, [0, 0, 0], [-1, 1, -1])], axis=1))\n",
    "    conv1 = Conv1D(64, 3, activation='tanh', padding='valid', kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.001, l2=0.0001))(periodic_padd(v_times_in))\n",
    "    conv1 = Conv1D(64, 3, activation='tanh', padding='valid', kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.001, l2=0.0001))(periodic_padd(conv1))\n",
    "    pool1 = AveragePooling1D(pool_size=2)(conv1)\n",
    "    periodic_padd = Lambda(lambda b: tf.concat(\n",
    "        [tf.slice(b, [0, int(input_shape[0]/2) - 1, 0], [-1, -1, -1]), b, tf.slice(b, [0, 0, 0], [-1, 1, -1])], axis=1))\n",
    "    conv2 = Conv1D(128, 3, activation='tanh', padding='valid', kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.001, l2=0.0001))(periodic_padd(BatchNormalization(axis=[1, 2])(pool1)))\n",
    "    conv2 = Conv1D(128, 3, activation='tanh', padding='valid', kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.001, l2=0.0001))(periodic_padd(BatchNormalization(axis=[1, 2])(conv2)))\n",
    "    pool2 = AveragePooling1D(pool_size=2)(conv2)\n",
    "    periodic_padd = Lambda(lambda b: tf.concat(\n",
    "        [tf.slice(b, [0, int(input_shape[0] / 4) - 1, 0], [-1, -1, -1]), b, tf.slice(b, [0, 0, 0], [-1, 1, -1])],\n",
    "        axis=1))\n",
    "    conv3 = Conv1D(256, 3, activation='tanh', padding='valid', kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.001, l2=0.0001))(periodic_padd(BatchNormalization(axis=[1, 2])(pool2)))\n",
    "    conv3 = Conv1D(256, 3, activation='tanh', padding='valid', kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.001, l2=0.0001))(periodic_padd(BatchNormalization(axis=[1, 2])(conv3)))\n",
    "    pool3 = AveragePooling1D(pool_size=2)(conv3)\n",
    "    periodic_padd = Lambda(lambda b: tf.concat(\n",
    "        [tf.slice(b, [0, int(input_shape[0] / 8) - 1, 0], [-1, -1, -1]), b, tf.slice(b, [0, 0, 0], [-1, 1, -1])],\n",
    "        axis=1))\n",
    "    conv4 = Conv1D(512, 3, activation='tanh', padding='valid', kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.001, l2=0.0001))(periodic_padd(BatchNormalization(axis=[1, 2])(pool3)))\n",
    "    conv4 = Conv1D(512, 3, activation='tanh', padding='valid', kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.001, l2=0.0001))(periodic_padd(BatchNormalization(axis=[1, 2])(conv4)))\n",
    "    pool4 = AveragePooling1D(pool_size=2)(conv4)\n",
    "    periodic_padd = Lambda(lambda b: tf.concat(\n",
    "        [tf.slice(b, [0, int(input_shape[0] / 16) - 1, 0], [-1, -1, -1]), b, tf.slice(b, [0, 0, 0], [-1, 1, -1])],\n",
    "        axis=1))\n",
    "    conv5 = Conv1D(1024, 3, activation='tanh', padding='valid', kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.001, l2=0.0001))(periodic_padd(BatchNormalization(axis=[1, 2])(pool4)))\n",
    "    conv5 = Conv1D(1024, 3, activation='tanh', padding='valid', kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.001, l2=0.0001))(periodic_padd(BatchNormalization(axis=[1, 2])(conv5)))\n",
    "    drop5 = Dropout(0.2)(conv5)\n",
    "    periodic_padd_2 = Lambda(lambda b: tf.concat([b, tf.slice(b, [0, 0, 0], [-1, 1, -1])], axis=1))\n",
    "    up6 = Conv1D(512, 2, activation='tanh', padding='valid', kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.001, l2=0.0001))(periodic_padd_2(\n",
    "        UpSampling1D(size=2)(BatchNormalization(axis=[1, 2])(drop5))))\n",
    "    periodic_padd = Lambda(lambda b: tf.concat(\n",
    "        [tf.slice(b, [0, int(input_shape[0] / 8) - 1, 0], [-1, -1, -1]), b, tf.slice(b, [0, 0, 0], [-1, 1, -1])],\n",
    "        axis=1))\n",
    "    merge6 = concatenate([conv4, up6], axis=-1)\n",
    "    conv6 = Conv1D(512, 3, activation='tanh', padding='valid', kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.001, l2=0.0001))(periodic_padd(BatchNormalization(axis=[1, 2])(merge6)))\n",
    "    conv6 = Conv1D(512, 3, activation='tanh', padding='valid', kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.001, l2=0.0001))(periodic_padd(BatchNormalization(axis=[1, 2])(conv6)))\n",
    "\n",
    "    up7 = Conv1D(256, 2, activation='tanh', padding='valid', kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.001, l2=0.0001))(periodic_padd_2(BatchNormalization(axis=[1, 2])(\n",
    "        UpSampling1D(size=2)(conv6))))\n",
    "    periodic_padd = Lambda(lambda b: tf.concat(\n",
    "        [tf.slice(b, [0, int(input_shape[0] / 4) - 1, 0], [-1, -1, -1]), b, tf.slice(b, [0, 0, 0], [-1, 1, -1])],\n",
    "        axis=1))\n",
    "    merge7 = concatenate([conv3, up7], axis=-1)\n",
    "    conv7 = Conv1D(256, 3, activation='tanh', padding='valid', kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.001, l2=0.0001))(periodic_padd(BatchNormalization(axis=[1, 2])(merge7)))\n",
    "    conv7 = Conv1D(256, 3, activation='tanh', padding='valid', kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.001, l2=0.0001))(periodic_padd(BatchNormalization(axis=[1, 2])(conv7)))\n",
    "\n",
    "    up8 = Conv1D(128, 2, activation='tanh', padding='valid', kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.001, l2=0.0001))(periodic_padd_2(BatchNormalization(axis=[1, 2])(\n",
    "        UpSampling1D(size=2)(conv7))))\n",
    "    periodic_padd = Lambda(lambda b: tf.concat(\n",
    "        [tf.slice(b, [0, int(input_shape[0] / 2) - 1, 0], [-1, -1, -1]), b, tf.slice(b, [0, 0, 0], [-1, 1, -1])],\n",
    "        axis=1))\n",
    "    merge8 = concatenate([conv2, up8], axis=-1)\n",
    "    conv8 = Conv1D(128, 3, activation='tanh', padding='valid', kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.001, l2=0.0001))(periodic_padd(BatchNormalization(axis=[1, 2])(merge8)))\n",
    "    conv8 = Conv1D(128, 3, activation='tanh', padding='valid', kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.001, l2=0.0001))(periodic_padd(BatchNormalization(axis=[1, 2])(conv8)))\n",
    "\n",
    "    up9 = Conv1D(64, 2, activation='tanh', padding='valid', kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.001, l2=0.0001))(periodic_padd_2(BatchNormalization(axis=[1, 2])(\n",
    "        UpSampling1D(size=2)(conv8))))\n",
    "    periodic_padd = Lambda(lambda b: tf.concat(\n",
    "        [tf.slice(b, [0, input_shape[0] - 1, 0], [-1, -1, -1]), b, tf.slice(b, [0, 0, 0], [-1, 1, -1])],\n",
    "        axis=1))\n",
    "    merge9 = concatenate([conv1, up9], axis=-1)\n",
    "    conv9 = Conv1D(48, 3, activation='tanh', padding='valid', kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.001, l2=0.0001))(periodic_padd(BatchNormalization(axis=[1, 2])(merge9)))\n",
    "    conv9 = Conv1D(16, 3, activation='tanh', padding='valid', kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.001, l2=0.0001))(periodic_padd(BatchNormalization(axis=[1, 2])(conv9)))\n",
    "    out = Conv1D(1, 1, kernel_initializer='he_normal')(conv9)\n",
    "    model = Model(inputs=inputs, outputs=out, name='UNet_1')\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr=1e-3), loss='mae', metrics=['mae'])\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    if (pretrained_weights):\n",
    "        model.load_weights(pretrained_weights)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f2bc66",
   "metadata": {},
   "source": [
    "We will also create a simple CNN model and a more complex version where velocity and amplitude are being multiplied. There is also a helper function for the periodic padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03bc27dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def periodic_padd_3_128(x):\n",
    "    return tf.tile(x, [1, 3, 1])[:, 127:257, :]\n",
    "\n",
    "def CNN(pretrained_weights=None, input_shape=(128, 2)):\n",
    "    inputs = Input(input_shape)\n",
    "    bn1 = BatchNormalization(axis=[1, 2])(inputs)\n",
    "    conv1 = Conv1D(2048, 3, activation='tanh', padding='valid', kernel_initializer='he_normal')(periodic_padd_3_128(bn1))\n",
    "    bn2 = BatchNormalization(axis=[1, 2])(conv1)\n",
    "    conv2 = Conv1D(1024, 3, activation='tanh', padding='valid', kernel_initializer='he_normal')(periodic_padd_3_128(bn2))\n",
    "    bn3 = BatchNormalization(axis=[1, 2])(conv2)\n",
    "    conv3 = Conv1D(256, 3, activation='tanh', padding='valid', kernel_initializer='he_normal')(periodic_padd_3_128(bn3))\n",
    "    bn4 = BatchNormalization(axis=[1, 2])(conv3)\n",
    "    conv4 = Conv1D(64, 3, activation='tanh', padding='valid', kernel_initializer='he_normal')(periodic_padd_3_128(bn4))\n",
    "    bn5 = BatchNormalization(axis=[1, 2])(conv4)\n",
    "    conv5 = Conv1D(1, 3, activation='tanh', padding='valid', kernel_initializer='he_normal')(periodic_padd_3_128(bn5))\n",
    "    out = BatchNormalization(axis=[1, 2])(conv5)\n",
    "    model = Model(inputs=inputs, outputs=out, name='Unet_5')\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr=1e-3), loss='mae', metrics=['mae'])\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    if (pretrained_weights):\n",
    "        model.load_weights(pretrained_weights)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def CNN2(pretrained_weights=None, input_shape=(128, 2)):\n",
    "    inputs = Input(input_shape)\n",
    "    input1 = Lambda(lambda b: tf.slice(b, [0, 0, 0], [-1, -1, 1]))(inputs)\n",
    "    velocities = Lambda(lambda b: tf.slice(b, [0, 0, 1], [-1, -1, -1]))(inputs)\n",
    "    conv1 = Conv1D(2048, 3, activation='tanh', padding='valid', use_bias=False, kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.001, l2=0.0001), kernel_initializer='he_uniform')(periodic_padd_3_128(input1))\n",
    "    conv2 = Conv1D(2048, 3, activation='tanh', padding='valid', use_bias=False, kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.001, l2=0.0001), kernel_initializer='he_uniform')(periodic_padd_3_128(velocities))\n",
    "    v_times_in = multiply([conv1, conv2])\n",
    "    conv3 = Conv1D(1024, 3, activation='tanh', use_bias=False, padding='valid', kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.001, l2=0.0001), kernel_initializer='he_uniform')(periodic_padd_3_128(v_times_in))\n",
    "    conv4 = Conv1D(256, 3, activation='tanh', use_bias=False, padding='valid', kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.001, l2=0.0001), kernel_initializer='he_uniform')(periodic_padd_3_128(conv3))\n",
    "    conv5 = Conv1D(64, 3, activation='tanh', use_bias=False, padding='valid',kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.001, l2=0.0001), kernel_initializer='he_uniform')(periodic_padd_3_128(conv4))\n",
    "    out = Conv1D(1, 1, use_bias=False, activation='tanh', padding='valid', kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.001, l2=0.0001), kernel_initializer='he_uniform')(conv5)\n",
    "    model = Model(inputs=inputs, outputs=out, name='Unet_5')\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr=1), loss='mae', metrics=['mse'])\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    if (pretrained_weights):\n",
    "        model.load_weights(pretrained_weights)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cd8d64",
   "metadata": {},
   "source": [
    "Now that we have created the deep learning models, we will define the data generator necessary to read in the data we created using Clawpack batch by batch. <br>\n",
    "The velocities are divided by the current grid size to (hopefully) allow weights to be applicable to grid sizes different than what was used in training. <br>\n",
    "No statistical normalization of velocities or amplitude is done by default. <br>\n",
    "To normalize all the data at once, use the function under the generator. <br>\n",
    "To normalize a batch at a time you can simply normalize x,y before returning them in '__Data_generation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3a90dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, data_dir, list_IDs, dt=1/128, batch_size=32, dim=128, shuffle=True, training=True):\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.list_IDs = list_IDs\n",
    "        self.shuffle = shuffle\n",
    "        self.dt = dt\n",
    "        self.on_epoch_end()\n",
    "        if training == True:\n",
    "            self.dir = data_dir+'/training/'\n",
    "        else:\n",
    "            self.dir = data_dir+'/validation/'\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        x = np.empty((self.batch_size, self.dim, 2))\n",
    "        y = np.empty((self.batch_size, self.dim, 1), dtype=int)\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            data = np.load(self.dir + 'ex_'+str(ID)+'.npy')\n",
    "            # I am dividing by the dimension so get velocities that are scaled to the current grid\n",
    "            data[:, 1] = data[:, 1] * self.dim * self.dt\n",
    "            x[i] = data[:, :-1]\n",
    "            y[i] = data[:, [-1]] - data[:, [0]]\n",
    "        return x, y\n",
    "def normalize(num_train, num_val, train_dir, val_dir):\n",
    "    mean_train = 0\n",
    "    std_train = 0\n",
    "    mean_val = 0\n",
    "    std_val = 0\n",
    "    for i in range(num_train):\n",
    "         mean_train = mean_train + np.load(train_dir + 'ex_'+str(i)+'.npy')\n",
    "    mean_train = mean_train / num_train\n",
    "    for i in range(num_train):\n",
    "         std_train = std_train + (np.load(train_dir + 'ex_'+str(i)+'.npy') - mean_train) ** 2\n",
    "    std_train = np.sqrt(std_train / num_train)\n",
    "    for i in range(num_train):\n",
    "        data = (np.load(train_dir + 'ex_'+str(i)+'.npy') - mean_train) / std_train\n",
    "        np.save(train_dir + 'ex_'+str(i)+'.npy', data)\n",
    "    for i in range(num_val):\n",
    "         mean_val = mean_val + np.load(val_dir + 'ex_'+str(i)+'.npy')\n",
    "    mean_val = mean_val / num_val\n",
    "    for i in range(num_val):\n",
    "         std_val = std_val + (np.load(val_dir + 'ex_'+str(i)+'.npy') - mean_val) ** 2\n",
    "    std_val = np.sqrt(std_val / num_val)\n",
    "    for i in range(num_val):\n",
    "        data = (np.load(val_dir + 'ex_'+str(i)+'.npy') - mean_val) / std_val\n",
    "        np.save(val_dir + 'ex_'+str(i)+'.npy', data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6312a0cb",
   "metadata": {},
   "source": [
    "Now that we have created the functionality that we need we can generate the data and train and evaluate the models. This is where you can set all of your parameters for the problem. num_train is number of training examples (each a single time step). num_val is the number of validation examples (also 1 time step). The batch_size is the number of training examples used in each batch fed into the deep learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a85ba9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = 20000\n",
    "num_val = 5000\n",
    "epochs = 1\n",
    "batch_size = 32\n",
    "dt = 1/128\n",
    "tfinal = 1.0\n",
    "data_dir = '/home/jacob/PycharmProjects/1D_DL_Advection_Emulation/Claw_Data/Scalar_Advect'\n",
    "model_dir = '/home/jacob/PycharmProjects/1D_DL_Advection_Emulation/DL_Models/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264f804e",
   "metadata": {},
   "source": [
    "Comment the next cell out if you don't need the data anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "581eb37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gen_data(data_dir, dimensions=128, nsteps=int(tfinal/dt), tfinal=tfinal, num_train=num_train, num_val=num_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcd9f34",
   "metadata": {},
   "source": [
    "Here is the function that trains our models. It returns a list of the returned models after saving a copy to the model_dir that you select. 'labels' is the variable used to control how the models are saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35b0c8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_train(models, labels, num_train, num_val, dt, batch_size, data_dir, model_dir):\n",
    "    model_builds = []\n",
    "\n",
    "    for i, m in enumerate(models):\n",
    "        model_build = m()\n",
    "        train_generator = DataGenerator(data_dir, np.arange(num_train)[1:], dt=dt, dim=128, batch_size=batch_size, training=True)\n",
    "        val_generator = DataGenerator(data_dir, np.arange(num_val), dt=dt, dim=128, batch_size=batch_size, training=False)\n",
    "        print(labels[i])\n",
    "        callbacks = [ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-7),\n",
    "                     EarlyStopping(monitor='val_loss', patience=10),\n",
    "                     TensorBoard(log_dir=model_dir + labels[i] + '_logs', update_freq='epoch')]\n",
    "        # Train model on dataset\n",
    "        print('training')\n",
    "        model_build.fit_generator(generator=train_generator, validation_data=val_generator, epochs=epochs, callbacks=callbacks)\n",
    "        print('saving')\n",
    "        model_build.save(model_dir + labels[i])\n",
    "        model_builds.append(model_build)\n",
    "    return model_builds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa843a9c",
   "metadata": {},
   "source": [
    "After the models have been trained they can be evaluated with the following function. You pass the model_builds as input to the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b209c567",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_eval(model_builds, models, num_train, num_val, batch_size, data_dir, dt, tfinal, resolutions=[32, 64, 128], plot_steps = [0, 1, 2, 3, 4, 5]):\n",
    "    # we will collect errors for each model as well as errors for the numerical method at 1x, 2x->1x, and 4x->1x resolution\n",
    "    #for res in [64, 128, 256]. Choose [128] to only test with the same resolution used for training\n",
    "    nsteps = int(tfinal/dt)\n",
    "    for res in resolutions:\n",
    "        print('resolution is: ', res)\n",
    "        #Normalize the velocities here\n",
    "        velocity_u = np.full((res,), 1) * res * dt\n",
    "        errors = np.zeros((nsteps-1, len(models) + 4))\n",
    "        saved_solns = np.zeros((len(plot_steps), len(models) + 1, res))\n",
    "        last_soln = np.zeros((res,))\n",
    "        ref_soln = np.zeros((res,))\n",
    "        for i, m1 in enumerate(model_builds):\n",
    "            # m1 = model\n",
    "            for step in range(nsteps-1):\n",
    "                if step == 0:\n",
    "                    data_inp = np.load(\n",
    "                        data_dir + '/testing/' + str(int(res * 8)) + '->' + str(res) + '_step:' + str(0) + '.npy')\n",
    "                    print('inp shape is: ', data_inp.shape)\n",
    "                else:\n",
    "                    data_inp = last_soln\n",
    "                ref_soln = np.load(\n",
    "                    data_dir + '/testing/' + str(int(res * 8)) + '->' + str(res) + '_step:' + str(step + 1) + '.npy')\n",
    "                last_soln = m1(\n",
    "                    np.concatenate([np.expand_dims(data_inp, axis=(0, -1)), np.expand_dims(velocity_u, axis=(0, -1))],\n",
    "                                   axis=-1))[0, :, 0] + data_inp\n",
    "                if step in plot_steps:\n",
    "                    saved_solns[plot_steps.index(step), -1] = ref_soln\n",
    "                    saved_solns[plot_steps.index(step), i] = last_soln\n",
    "                    errors[step, i] = mae(last_soln, ref_soln)\n",
    "                else:\n",
    "                    errors[step, i] = mae(ref_soln, last_soln)\n",
    "                errors[step, -1] = mae(np.load(\n",
    "                    data_dir + '/testing/' + str(int(res * 4)) + '->' + str(res) + '_step:' + str(step + 1) + '.npy'),\n",
    "                                       ref_soln)\n",
    "                errors[step, -2] = mae(np.load(\n",
    "                    ddata_dir + '/testing/' + str(int(res * 2)) + '->' + str(res) + '_step:' + str(step + 1) + '.npy'),\n",
    "                                       ref_soln)\n",
    "                errors[step, -3] = mae(np.load(\n",
    "                    data_dir + '/testing/' + str(int(res * 1)) + '->' + str(res) + '_step:' + str(step + 1) + '.npy'),\n",
    "                                       ref_soln)\n",
    "                errors[step, -4] = np.mean(np.abs(ref_soln))\n",
    "        x = np.arange(nsteps-1) + 1\n",
    "        for i in range(len(models)):\n",
    "            plt.plot(x, errors[:, i], label=labels[i], color='red')\n",
    "        plt.plot(x, errors[:, -4], label='Avg abs soln value, res=' + str(res), color='black')\n",
    "        plt.plot(x, errors[:, -3], label='1x res FV soln', color='blue')\n",
    "        plt.plot(x, errors[:, -2], label='2x res FV soln', color='green')\n",
    "        plt.plot(x, errors[:, -1], label='4x res FV soln', color='orange')\n",
    "        plt.legend()\n",
    "        plt.title(str(res) + '-res MAEs')\n",
    "        plt.xlabel('Simulation Step')\n",
    "        plt.ylabel('MAE')\n",
    "        plt.show()\n",
    "        xlist = np.linspace(0, 1, res)\n",
    "        for j in range(len(plot_steps)):\n",
    "            for z in range(len(models)):\n",
    "                fig, ax = plt.subplots(1, 1)\n",
    "                ax.plot(xlist, saved_solns[j, z])\n",
    "                ax.set_title(str(res) + '-res Solution, ' + str(z) + 'th model, ' + 'step=' + str(plot_steps[j] + 1))\n",
    "                ax.set_xlabel('Location')\n",
    "                ax.set_ylabel('y axis')\n",
    "                plt.show()\n",
    "            fig, ax = plt.subplots(1, 1)\n",
    "            ax.plot(xlist, saved_solns[j, -1])\n",
    "            ax.set_title(str(res) + '-res Ref Solution, ' + 'step=' + str(plot_steps[j] + 1))\n",
    "            ax.set_xlabel('Location')\n",
    "            ax.set_ylabel('y axis')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2107bacf",
   "metadata": {},
   "source": [
    "Now we finally train and evaluate the models we want to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "998ac4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-15 09:47:09.514855: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-10-15 09:47:09.518679: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-10-15 09:47:09.582902: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:42:00.0 name: NVIDIA GeForce RTX 3080 Ti computeCapability: 8.6\n",
      "coreClock: 1.8GHz coreCount: 80 deviceMemorySize: 11.76GiB deviceMemoryBandwidth: 849.46GiB/s\n",
      "2022-10-15 09:47:09.582941: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-10-15 09:47:09.602708: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-10-15 09:47:09.602776: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-10-15 09:47:09.615371: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-10-15 09:47:09.618231: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-10-15 09:47:09.639589: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-10-15 09:47:09.643220: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-10-15 09:47:09.679467: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-10-15 09:47:09.681810: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-10-15 09:47:09.682394: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-15 09:47:09.684466: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-10-15 09:47:09.685566: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:42:00.0 name: NVIDIA GeForce RTX 3080 Ti computeCapability: 8.6\n",
      "coreClock: 1.8GHz coreCount: 80 deviceMemorySize: 11.76GiB deviceMemoryBandwidth: 849.46GiB/s\n",
      "2022-10-15 09:47:09.685646: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-10-15 09:47:09.685708: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-10-15 09:47:09.685742: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-10-15 09:47:09.685775: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-10-15 09:47:09.685808: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-10-15 09:47:09.685840: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-10-15 09:47:09.685873: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-10-15 09:47:09.685895: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-10-15 09:47:09.687417: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-10-15 09:47:09.687668: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-10-15 09:53:57.383043: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-10-15 09:53:57.383087: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2022-10-15 09:53:57.383102: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2022-10-15 09:53:57.386510: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10436 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3080 Ti, pci bus id: 0000:42:00.0, compute capability: 8.6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"UNet_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 128, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 128, 2)       1024        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 multiple             0           batch_normalization[0][0]        \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 128, 64)      448         lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 128, 64)      32768       conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 128, 64)      12352       lambda[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling1d (AveragePooli (None, 64, 64)       0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 64, 64)       16384       average_pooling1d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               multiple             0           batch_normalization_2[0][0]      \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 64, 128)      24704       lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 64, 128)      32768       conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 64, 128)      49280       lambda_1[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling1d_1 (AveragePoo (None, 32, 128)      0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 128)      16384       average_pooling1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               multiple             0           batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 32, 256)      98560       lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 256)      32768       conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 32, 256)      196864      lambda_2[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling1d_2 (AveragePoo (None, 16, 256)      0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 16, 256)      16384       average_pooling1d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               multiple             0           batch_normalization_6[0][0]      \n",
      "                                                                 batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 16, 512)      393728      lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 16, 512)      32768       conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 16, 512)      786944      lambda_3[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling1d_3 (AveragePoo (None, 8, 512)       0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 8, 512)       16384       average_pooling1d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               multiple             0           batch_normalization_8[0][0]      \n",
      "                                                                 batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 8, 1024)      1573888     lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 8, 1024)      32768       conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 8, 1024)      3146752     lambda_4[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 8, 1024)      0           conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d (UpSampling1D)    (None, 16, 1024)     0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 1024)     65536       up_sampling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               multiple             0           batch_normalization_10[0][0]     \n",
      "                                                                 batch_normalization_13[0][0]     \n",
      "                                                                 batch_normalization_16[0][0]     \n",
      "                                                                 batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 16, 512)      1049088     lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 16, 1024)     0           conv1d_7[0][0]                   \n",
      "                                                                 conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 1024)     65536       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               multiple             0           batch_normalization_11[0][0]     \n",
      "                                                                 batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 16, 512)      1573376     lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 16, 512)      32768       conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 16, 512)      786944      lambda_6[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_1 (UpSampling1D)  (None, 32, 512)      0           conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 32, 512)      65536       up_sampling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 32, 256)      262400      lambda_5[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 512)      0           conv1d_5[0][0]                   \n",
      "                                                                 conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 32, 512)      65536       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               multiple             0           batch_normalization_14[0][0]     \n",
      "                                                                 batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 32, 256)      393472      lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 32, 256)      32768       conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 32, 256)      196864      lambda_7[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_2 (UpSampling1D)  (None, 64, 256)      0           conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 64, 256)      65536       up_sampling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 64, 128)      65664       lambda_5[2][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 64, 256)      0           conv1d_3[0][0]                   \n",
      "                                                                 conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 64, 256)      65536       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               multiple             0           batch_normalization_17[0][0]     \n",
      "                                                                 batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 64, 128)      98432       lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 64, 128)      32768       conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 64, 128)      49280       lambda_8[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_3 (UpSampling1D)  (None, 128, 128)     0           conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 128, 128)     65536       up_sampling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 128, 64)      16448       lambda_5[3][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 128, 128)     0           conv1d_1[0][0]                   \n",
      "                                                                 conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 128, 128)     65536       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               multiple             0           batch_normalization_20[0][0]     \n",
      "                                                                 batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 128, 48)      18480       lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 128, 48)      24576       conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 128, 16)      2320        lambda_9[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 128, 1)       17          conv1d_21[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 11,673,873\n",
      "Trainable params: 11,235,089\n",
      "Non-trainable params: 438,784\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "UNet 1\n",
      "training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-15 09:53:57.996557: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n",
      "2022-10-15 09:53:57.996592: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n",
      "2022-10-15 09:53:57.997095: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1365] Profiler found 1 GPUs\n",
      "2022-10-15 09:53:58.001232: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcupti.so.10.1\n",
      "2022-10-15 09:53:58.102181: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1415] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_INSUFFICIENT_PRIVILEGES\n",
      "2022-10-15 09:53:58.102651: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n",
      "/home/jacob/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      "2022-10-15 09:53:58.188304: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-10-15 09:53:58.210657: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2994075000 Hz\n",
      "2022-10-15 09:54:02.589632: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-10-15 10:10:39.790253: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256\n",
      "2022-10-15 10:10:39.835411: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: \n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2022-10-15 10:10:40.294735: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-10-15 10:12:09.546484: W tensorflow/core/framework/op_kernel.cc:1763] OP_REQUIRES failed at cwise_op_gpu_base.cc:89 : Internal: Failed to load in-memory CUBIN: CUDA_ERROR_NO_BINARY_FOR_GPU: no kernel image is available for execution on the device\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": " Failed to load in-memory CUBIN: CUDA_ERROR_NO_BINARY_FOR_GPU: no kernel image is available for execution on the device\n\t [[node UNet_1/conv1d/Tanh (defined at tmp/ipykernel_4212/957115494.py:14) ]] [Op:__inference_train_function_12524]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m models \u001b[38;5;241m=\u001b[39m [UNet]\n\u001b[1;32m      5\u001b[0m labels \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUNet 1\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 6\u001b[0m model_builds \u001b[38;5;241m=\u001b[39m \u001b[43mf_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36mf_train\u001b[0;34m(models, labels, num_train, num_val, dt, batch_size, data_dir, model_dir)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Train model on dataset\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m \u001b[43mmodel_build\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msaving\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     16\u001b[0m model_build\u001b[38;5;241m.\u001b[39msave(model_dir \u001b[38;5;241m+\u001b[39m labels[i])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1847\u001b[0m, in \u001b[0;36mModel.fit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1838\u001b[0m \u001b[38;5;124;03m\"\"\"Fits the model on data yielded batch-by-batch by a Python generator.\u001b[39;00m\n\u001b[1;32m   1839\u001b[0m \n\u001b[1;32m   1840\u001b[0m \u001b[38;5;124;03mDEPRECATED:\u001b[39;00m\n\u001b[1;32m   1841\u001b[0m \u001b[38;5;124;03m  `Model.fit` now supports generators, so there is no longer any need to use\u001b[39;00m\n\u001b[1;32m   1842\u001b[0m \u001b[38;5;124;03m  this endpoint.\u001b[39;00m\n\u001b[1;32m   1843\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1844\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`Model.fit_generator` is deprecated and \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1845\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwill be removed in a future version. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1846\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlease use `Model.fit`, which supports generators.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1847\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1849\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1850\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1851\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1852\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1853\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1854\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1855\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1856\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1857\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1858\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1859\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1860\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1861\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1100\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1093\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1094\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1095\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1096\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1097\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1098\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1099\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1100\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1101\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1102\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:828\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name) \u001b[38;5;28;01mas\u001b[39;00m tm:\n\u001b[0;32m--> 828\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    829\u001b[0m   compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_experimental_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m   new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:888\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    884\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[1;32m    885\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    886\u001b[0m     \u001b[38;5;66;03m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[1;32m    887\u001b[0m     \u001b[38;5;66;03m# stateless function.\u001b[39;00m\n\u001b[0;32m--> 888\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    890\u001b[0m   _, _, _, filtered_flat_args \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m    891\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn\u001b[38;5;241m.\u001b[39m_function_spec\u001b[38;5;241m.\u001b[39mcanonicalize_function_inputs(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    892\u001b[0m           \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2942\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2940\u001b[0m   (graph_function,\n\u001b[1;32m   2941\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2943\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1918\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1914\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1915\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1916\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1917\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1918\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1919\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1920\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m     args,\n\u001b[1;32m   1922\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1923\u001b[0m     executing_eagerly)\n\u001b[1;32m   1924\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py:555\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    554\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 555\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    561\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    562\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    563\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    564\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    567\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    568\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     58\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 59\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     62\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInternalError\u001b[0m:  Failed to load in-memory CUBIN: CUDA_ERROR_NO_BINARY_FOR_GPU: no kernel image is available for execution on the device\n\t [[node UNet_1/conv1d/Tanh (defined at tmp/ipykernel_4212/957115494.py:14) ]] [Op:__inference_train_function_12524]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "#You can use a subset of the models to work with a smaller group at a time\n",
    "#models = [UNet, UNet2, CNN, CNN2]\n",
    "#labels = ['UNet1', 'UNet2', 'CNN1', 'CNN2']\n",
    "models = [UNet]\n",
    "labels = ['UNet1']\n",
    "model_builds = f_train(models, labels, num_train, num_val, dt, batch_size, data_dir, model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8679930c",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_eval(model_builds, models, num_train, num_val, batch_size, data_dir, dt, tfinal, [128], [0, 1, 2, 3, 4, 5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
